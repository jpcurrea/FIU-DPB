import os
import subprocess
from matplotlib import pyplot as plt
import numpy as np
from skvideo import io

from PyQt5.QtWidgets import QWidget, QFileDialog, QApplication
from points_GUI import distance_calibration_GUI, ROI_GUI, rectangle_bounding_box_GUI
from scipy import spatial, ndimage

filetypes = [
    ('h264 videos', '*.h264'),
    ('mpeg videos', '*.mpg *.mpeg *.mp4'),
    ('avi videos', '*.avi'),
    ('quicktime videos', '*.mov *.qt'),
    ('all files', '*')
]

# format the filetypes for the pyqt file dialog box
ftypes = []
for (fname, ftype) in filetypes:
    ftypes += [f"{fname} ({ftype})"]
ftypes = ";;".join(ftypes)


def rotate(arr, theta, axis=0):
    """Generate a rotation matrix and rotate input array along a single axis. 
    If only one axis, it will rotate counter-clockwise"""
    # theta = -theta
    rot_matrix = np.array(
        [[np.cos(theta), -np.sin(theta)],
         [np.sin(theta), np.cos(theta)]])
    nx, ny, = np.dot(arr, rot_matrix).T
    nx = np.squeeze(nx)
    ny = np.squeeze(ny)
    return np.array([nx, ny]).T


class fileSelector(QWidget):
    """Offers a file selection dialog box with filters based on common image filetypes.
    """

    def __init__(self, filetypes=ftypes):
        super().__init__()
        self.app = QApplication.instance()
        if self.app is None:
            self.app = QApplication([])
        self.title = 'Select the videos you want to process.'
        self.left = 10
        self.top = 10
        self.width = 640
        self.height = 480
        self.filetypes = filetypes
        self.initUI()

    def initUI(self):
        self.setWindowTitle(self.title)
        self.setGeometry(self.left, self.top, self.width, self.height)
        self.openFileNamesDialog()
        self.show()

    def openFileNamesDialog(self):
        options = QFileDialog.Options()
        # options |= QFileDialog.DontUseNativeDialog
        self.files, self.ftype = QFileDialog.getOpenFileNames(
            self,
            "QFileDialog.getOpenFileNames()",
            "",
            self.filetypes,
            options=options)


class VideoCropper():
    """A GUI for selecting a bounding rectangle in video thumbnails and then 
    rotating the videos and cropping them around that frame using skvideo and 
    ffmpeg.
    """

    def __init__(self, thumbnail_folder="thumbnails",
                 frames=None, cropped_folder='cropped'):
        self.app = QApplication.instance()
        if self.app is None:
            self.app = QApplication([])
        file_UI = fileSelector()
        file_UI.close()
        self.video_files = file_UI.files
        self.folder = os.path.dirname(self.video_files[0])
        os.chdir(self.folder)
        self.cropped_folder = os.path.join(self.folder, cropped_folder)
        if os.path.isdir(self.cropped_folder) is False:
            os.mkdir(self.cropped_folder)
        self.thumbnail_folder = os.path.join(self.folder, thumbnail_folder)
        # if folder of thumbnails does not exist, make a folder
        self.thumbnail_folder = os.path.join(self.folder, thumbnail_folder)
        if os.path.isdir(self.thumbnail_folder) is False:
            os.mkdir(self.thumbnail_folder)
        # make a thumbnail for each video if we haven't already
        self.thumbnail_files = os.listdir(self.thumbnail_folder)
        self.thumbnail_files = [
            fn for fn in self.thumbnail_files if fn.endswith(".jpg")]
        self.thumbnail_files = [
            os.path.join(self.thumbnail_folder, fn) for fn in self.thumbnail_files]
        for vid_file in self.video_files:
            new_fn = os.path.basename(vid_file)
            ftype = new_fn.split(".")[-1]
            new_fn = new_fn.replace(ftype, "jpg")
            new_fn = os.path.join(self.thumbnail_folder, new_fn)
            if new_fn not in self.thumbnail_files:
                save_thumbnail(vid_file, new_fn)
        # if frame points are not input, use rectangle_bounding_box_GUI
        frames_fn = os.path.join(self.thumbnail_folder, "frame_corners.npy")
        if os.path.exists(frames_fn):
            frames = np.load(frames_fn)
            self.frames_fn = frames_fn
        elif frames is None:
            self.gui = rectangle_bounding_box_GUI(self.thumbnail_folder)
            plt.show()
            frames = self.gui.frames
        self.frames = frames

    def crop_and_rotate(self):
        print("cropping and rotating:")
        for vid_fn, frame in zip(self.video_files, self.frames.transpose((1, 0, 2))):
            # grab video data
            base = os.path.basename(vid_fn)
            print(vid_fn)
            ftype = "." + base.split(".")[-1]
            new_fn = base.replace(ftype, f"_cropped{ftype}")
            new_fn = os.path.join(self.cropped_folder, new_fn)
            if os.path.exists(new_fn) is False:
                vid = io.vread(vid_fn)
                # first find lower and upper bounds for initial cropping
                lower = np.floor(frame.min(0)).astype(int)
                upper = np.ceil(frame.max(0)).astype(int)
                # initial cropping:
                vid = vid[:, lower[1]:upper[1], lower[0]:upper[0]]
                frame = frame - lower
                # find small edges to calculate angle of rotation
                tree = spatial.KDTree(frame)
                dists, indexes = tree.query(frame, k=3)
                small_inds = np.copy(indexes[:, :2])
                small_inds.sort(1)
                small_inds = np.unique(small_inds, axis=0)
                mid_points = []
                for ind in small_inds:
                    mid_points += [np.mean(frame[ind], axis=0)]
                mid_points = np.array(mid_points)
                # find the angle of the midline
                xs, ys = mid_points.T
                angle_rad = np.arctan2(np.diff(ys).mean(), np.diff(xs).mean())
                angle_deg = angle_rad * 180 / np.pi
                # rotate the video
                vid = ndimage.rotate(vid, angle_deg, axes=(1, 2))
                # and rotate the frame
                new_frame = rotate(frame - frame.mean(0), angle_rad)
                height, width = vid.shape[1:3]
                new_frame += np.array([width/2., height/2.])
                new_lower = np.floor(new_frame.min(0)).astype(int)
                new_upper = np.ceil(new_frame.max(0)).astype(int)
                # final crop of the video using the rotate frame
                vid = vid[:, new_lower[1]:new_upper[1],
                          new_lower[0]:new_upper[0]]
                # save video in cropped_folder
                io.vwrite(new_fn, vid)
                print(f"new video saved at {new_fn}")
                del vid


def save_thumbnail(fn, new_fn=None):
    if new_fn is None:
        ftype = fn.split(".")[-1]
        ftype = f".{ftype}"
        new_fn = fn.replace(ftype, "_thumbnail.jpg")
    cmd = [
        "ffmpeg", "-y", "-i", fn,
        "-vf", "select=gte(n\,100)",
        "-vframes", "1", new_fn
    ]
    subprocess.call(cmd)


# folder = "./test/"
# 0. make thumbnail for each file in a set of videos
crop = VideoCropper()
crop.crop_and_rotate()
# goes under crop_and_rotate:

# frame = crop.frames[:, 1]
# vid_fn = crop.video_files[1]
# # grab video data
# vid = io.vread(vid_fn)
# # first find lower and upper bounds for initial cropping
# lower = np.floor(frame.min(0)).astype(int)
# upper = np.ceil(frame.max(0)).astype(int)
# # initial cropping:
# vid = vid[:, lower[1]:upper[1], lower[0]:upper[0]]
# frame = frame - lower
# # find small edges to calculate angle of rotation
# tree = spatial.KDTree(frame)
# dists, indexes = tree.query(frame, k=3)
# small_inds = np.copy(indexes[:, :2])
# small_inds.sort(1)
# small_inds = np.unique(small_inds, axis=0)
# mid_points = []
# for ind in small_inds:
#     mid_points += [np.mean(frame[ind], axis=0)]
# mid_points = np.array(mid_points)
# # find the angles and radial distances of mid points from center
# xs, ys = mid_points.T
# angle_rad = np.arctan2(np.diff(ys).mean(), np.diff(xs).mean())
# angle_deg = angle_rad * 180 / np.pi
# # rotate the video
# vid = ndimage.rotate(vid, -angle_deg, axes=(1, 2))
# # and rotate the frame
# new_frame = rotate(frame, angle_rad)
# new_lower = np.floor(new_frame.min(0)).astype(int)
# new_upper = np.ceil(new_frame.max(0)).astype(int)
# # final crop of the video using the rotate frame
# vid = vid[:, new_lower[1]:new_upper[1], new_lower[0]:new_upper[0]]


# plt.scatter(frame.T[0], frame.T[1], color='k')
# plt.scatter(mid_points.T[0], mid_points.T[1], color='b')
# ax = plt.gca()
# ax.set_aspect('equal')
# plt.show()

# app = QApplication([])
# file_UI = fileSelector()
# file_UI.close()
# fns = file_UI.files

# parent_folder = os.path.dirname(fns[0])
# folder = os.path.join(parent_folder, "thumbnails")
# if os.path.isdir(folder) is False:
#     os.mkdir(folder)

# files = os.listdir(folder)
# files = [os.path.join(folder, fn) for fn in files]


# for fn in fns:
#     l = fn.split(".")
#     l[-1] = "jpg"
#     new_fn = ".".join(l)
#     new_fn = os.path.join(folder, new_fn)
#     base = os.path.basename(new_fn)
#     new_fn = os.path.join(folder, base)
#     if new_fn not in files:
#         print(new_fn)
#         cmd = [
#             "ffmpeg", "-y", "-i", fn,
#             "-vf", "select=gte(n\,100)",
#             "-vframes", "1", new_fn
#         ]
#         subprocess.call(cmd)

# 0. crop the files using a minimum bounding box around user-chosen points


# 2. offer GUI for getting a size reference from each thumbnail
# # (optional: if they don't do this, output will be in terms of pixels)
# calib = distance_calibration_GUI(dirname=folder, scale=121.92)
# plt.show()

# lengths = calib.lengths


# lengths = np.load(os.path.join(folder, "calibration_lengths.npy"))
# 3. offer GUI for selecting ROI's with optional hidden zones
# (optional: if they don't do this, output will be just x and y coordinates)
# roi = ROI_GUI(folder, num_points=2, pixel_length=lengths)
# plt.show()
# # 4. ask "how many moving objects are you actually interested in?"

# 5. consolidate the multiple trajectories using the following logic:
# # - label outlier speeds, which should come in pairs, and move points within those bounds to a new list, called aberations
# # - if len(hidden_zones) > 0, remove any lines in aberations that start and end in the hidden zones
# # - all trajectories should now correspond to the subject(s) of interest. If not, warn the user and offer a GUI to remove the faulty trajectories
# 6. save the x and y coordinates as one csv and npy file per video
# 7. if there are ROI's, calculate the distance of the subject from each ROI
